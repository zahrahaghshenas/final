{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB2KJ3bxHnvO",
        "outputId": "7a63312d-a930-4ac0-cbc7-06f691654d91"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dgl in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.65.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "wiAGJGpVFTM9"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import dgl.function as fn\n",
        "import torch.nn.functional as F\n",
        "import shutil\n",
        "from torch.utils.data import DataLoader\n",
        "import cloudpickle\n",
        "from dgl.nn import GraphConv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ63F7XpFTM-"
      },
      "source": [
        "#### Set Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "f-_ebl7EFTM-"
      },
      "outputs": [],
      "source": [
        "current_dir = \"./\"\n",
        "checkpoint_path = current_dir + \"save_models/model_checkpoints/\" + \"checkpoint\"\n",
        "os.makedirs(checkpoint_path, exist_ok=True)\n",
        "\n",
        "best_model_path = current_dir + \"save_models/best_model/\"\n",
        "\n",
        "folder_data_temp = current_dir +\"data_temp/\"\n",
        "shutil.rmtree(folder_data_temp, ignore_errors=True)\n",
        "\n",
        "path_save = current_dir + \"free.zip\"\n",
        "shutil.unpack_archive(path_save, folder_data_temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E4fZ5NoFTM-"
      },
      "source": [
        "#### Custom PyTorch Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "YmTs_DbbFTM-"
      },
      "outputs": [],
      "source": [
        "\"\"\" Regression Dataset \"\"\"\n",
        "class DGLDatasetReg(torch.utils.data.Dataset):\n",
        "    def __init__(self, address, transform=None, train=False, scaler=None, scaler_regression=None):\n",
        "            self.train = train\n",
        "            self.scaler = scaler\n",
        "            self.data_set, train_labels_masks_globals = dgl.load_graphs(address+\".bin\")\n",
        "            num_graphs = len(self.data_set)\n",
        "            self.labels = train_labels_masks_globals[\"labels\"].view(num_graphs,-1)\n",
        "            self.masks = train_labels_masks_globals[\"masks\"].view(num_graphs,-1)\n",
        "            self.globals = train_labels_masks_globals[\"globals\"].view(num_graphs,-1)\n",
        "            self.transform = transform\n",
        "            self.scaler_regression = scaler_regression\n",
        "    def scaler_method(self):\n",
        "        if self.train:\n",
        "            scaler = preprocessing.StandardScaler().fit(self.labels)\n",
        "            self.scaler = scaler\n",
        "        return self.scaler\n",
        "    def __len__(self):\n",
        "        return len(self.data_set)\n",
        "    def __getitem__(self, idx):\n",
        "        if self.scaler_regression:\n",
        "            \"\"\" With Scaler\"\"\"\n",
        "            return  self.data_set[idx], torch.tensor(self.scaler.transform(self.labels)[idx]).float(), self.masks[idx], self.globals[idx]\n",
        "        else:\n",
        "            \"\"\" Without Scaler \"\"\"\n",
        "            return  self.data_set[idx], self.labels[idx].float(), self.masks[idx], self.globals[idx]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iafgb5p0FTM-"
      },
      "source": [
        "#### Defining Train, Validation, and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0h0yU1MFTM_",
        "outputId": "b1992417-47d0-4cec-f2c6-b736a9618ed1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "513 64 65\n"
          ]
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "path_data_temp = folder_data_temp + \"scaffold\" + \"_\" + str(0)\n",
        "train_set = DGLDatasetReg(address=path_data_temp + \"_train\", train=True)\n",
        "\n",
        "# Build scaler on the training set\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(train_set.labels)\n",
        "\n",
        "# Apply scaler to validation and test sets\n",
        "val_set = DGLDatasetReg(address=path_data_temp + \"_val\", scaler=scaler, scaler_regression=True)\n",
        "test_set = DGLDatasetReg(address=path_data_temp + \"_test\", scaler=scaler, scaler_regression=True)\n",
        "\n",
        "print(len(train_set), len(val_set), len(test_set))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztr_DEKdFTM_"
      },
      "source": [
        "#### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate(batch):\n",
        "    # batch is a list of tuples (graphs, labels, masks, globals)\n",
        "    # Concatenate a sequence of graphs\n",
        "    graphs = [e[0] for e in batch]\n",
        "    g = dgl.batch(graphs)\n",
        "\n",
        "    # Concatenate a sequence of tensors (labels) along a new dimension\n",
        "    labels = [e[1] for e in batch]\n",
        "    labels = torch.stack(labels, 0).float()  # Convert labels to float\n",
        "\n",
        "    # Concatenate a sequence of tensors (masks) along a new dimension\n",
        "    masks = [e[2] for e in batch]\n",
        "    masks = torch.stack(masks, 0)\n",
        "\n",
        "    # Concatenate a sequence of tensors (globals) along a new dimension\n",
        "    globals = [e[3] for e in batch]\n",
        "    globals = torch.stack(globals, 0)\n",
        "\n",
        "    return g, labels, masks, globals\n",
        "\n",
        "\n",
        "def loader(batch_size=64):\n",
        "    train_dataloader = DataLoader(train_set,\n",
        "                                  batch_size=batch_size,\n",
        "                                  collate_fn=collate,\n",
        "                                  drop_last=False,\n",
        "                                  shuffle=True,\n",
        "                                  num_workers=1)\n",
        "\n",
        "    val_dataloader = DataLoader(val_set,\n",
        "                                batch_size=batch_size,\n",
        "                                collate_fn=collate,\n",
        "                                drop_last=False,\n",
        "                                shuffle=False,\n",
        "                                num_workers=1)\n",
        "\n",
        "    test_dataloader = DataLoader(test_set,\n",
        "                                 batch_size=batch_size,\n",
        "                                 collate_fn=collate,\n",
        "                                 drop_last=False,\n",
        "                                 shuffle=False,\n",
        "                                 num_workers=1)\n",
        "    return train_dataloader, val_dataloader, test_dataloader\n"
      ],
      "metadata": {
        "id": "1ICzl53DIabl"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "nkc2-MALFTM_"
      },
      "outputs": [],
      "source": [
        "train_dataloader, val_dataloader, test_dataloader = loader(batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw6ywJGtFTNA"
      },
      "source": [
        "#### Defining A GNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m91tUfucFTNA"
      },
      "source": [
        "##### Some Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "x22as8NzFTNA"
      },
      "outputs": [],
      "source": [
        "#Bace dataset has 1 task. Some other datasets may have some more number of tasks, e.g., tox21 has 12 tasks.\n",
        "num_tasks = 1\n",
        "\n",
        "# Size of global feature of each graph\n",
        "global_size = 200\n",
        "\n",
        "# Number of epochs to train the model\n",
        "num_epochs = 100\n",
        "\n",
        "# Number of steps to wait if the model performance on the validation set does not improve\n",
        "patience = 10\n",
        "\n",
        "#Configurations to instantiate the model\n",
        "config = {\"node_feature_size\":127, \"edge_feature_size\":12, \"hidden_size\":100}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "f7-apbTJFTNA"
      },
      "outputs": [],
      "source": [
        "import dgl\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size)\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.num_tasks)\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph = dgl.add_self_loop(mol_dgl_graph)  # Add self-loops\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qLGgRZVFTNA"
      },
      "source": [
        "#### Function to Compute Score of the Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "1WxU8tk1QDD7"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "j3hvt6XEFTNA"
      },
      "outputs": [],
      "source": [
        "# def compute_score(model, data_loader, val_size, num_tasks):\n",
        "#     model.eval()\n",
        "#     prediction_all = torch.empty(0, num_tasks)\n",
        "#     labels_all = torch.empty(0, num_tasks)\n",
        "#     masks_all = torch.empty(0, *data_loader.dataset.masks.shape[2:])  # Adjust the dimensions\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for batch_data in data_loader:\n",
        "#             graphs, labels, masks, globals = batch_data\n",
        "#             graphs = graphs.to(device)\n",
        "#             labels = labels.to(device)\n",
        "#             masks = masks.to(device)\n",
        "#             globals = globals.to(device)\n",
        "\n",
        "#             # Forward pass\n",
        "#             outputs = model(graphs, globals)\n",
        "#             prediction = outputs.squeeze(dim=1)  # Remove the extra dimension\n",
        "\n",
        "#             # Apply mask to the prediction tensor\n",
        "#             masked_prediction = torch.masked_select(prediction, masks.bool())\n",
        "\n",
        "#             # Reshape the masked_prediction tensor\n",
        "#             masked_prediction = masked_prediction.view(-1, num_tasks)\n",
        "\n",
        "#             # Concatenate predictions and labels\n",
        "#             prediction_all = torch.cat((prediction_all, masked_prediction), 0)\n",
        "#             labels_all = torch.cat((labels_all, labels[masks.bool()].unsqueeze(1)), 0)  # Unsqueeze the tensor\n",
        "\n",
        "#             # Expand mask dimensions\n",
        "#             masks_all = torch.cat((masks_all, masks.expand_as(masked_prediction)), 0)\n",
        "\n",
        "#         # Compute RMSE for each task\n",
        "#         rmse = torch.sqrt(F.mse_loss(prediction_all, labels_all, reduction='mean'))\n",
        "\n",
        "#     return rmse.item()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def compute_score(model, data_loader):\n",
        "#     \"\"\"\n",
        "#     Compute the RMSE score for the regression task in the FreeSolv dataset.\n",
        "\n",
        "#     Args:\n",
        "#         model (nn.Module): The trained model.\n",
        "#         data_loader (DataLoader): The data loader for the dataset.\n",
        "\n",
        "#     Returns:\n",
        "#         float: The RMSE score.\n",
        "#     \"\"\"\n",
        "#     model.eval()\n",
        "#     prediction_all = []\n",
        "#     labels_all = []\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for batch_data in data_loader:\n",
        "#             graphs, labels, masks, globals = batch_data\n",
        "#             graphs = graphs.to(device)\n",
        "#             labels = labels.to(device)\n",
        "\n",
        "#             # Forward pass\n",
        "#             outputs = model(graphs)\n",
        "#             prediction = outputs.squeeze(dim=1)\n",
        "\n",
        "#             # Append predictions and labels to lists\n",
        "#             prediction_all.append(prediction)\n",
        "#             labels_all.append(labels)\n",
        "\n",
        "#         # Concatenate predictions and labels\n",
        "#         prediction_all = torch.cat(prediction_all, dim=0)\n",
        "#         labels_all = torch.cat(labels_all, dim=0)\n",
        "\n",
        "#         # Compute RMSE for the regression task\n",
        "#         rmse = torch.sqrt(F.mse_loss(prediction_all, labels_all, reduction='mean'))\n",
        "\n",
        "#     return rmse.item()\n",
        "\n"
      ],
      "metadata": {
        "id": "bpHFmN2sKilt"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_score(model, data_loader, val_size=None, num_tasks=None):\n",
        "    \"\"\"\n",
        "    Compute the RMSE score for the regression task.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The trained model.\n",
        "        data_loader (DataLoader): The data loader for the dataset.\n",
        "        val_size (int, optional): The size of the validation set. Default is None.\n",
        "        num_tasks (int, optional): The number of regression tasks. Default is None.\n",
        "\n",
        "    Returns:\n",
        "        float: The RMSE score.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    prediction_all = []\n",
        "    labels_all = []\n",
        "    masks_all = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_data in data_loader:\n",
        "            graphs, labels, masks, globals = batch_data\n",
        "            graphs = graphs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            masks = masks.to(device)\n",
        "            globals = globals.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(graphs, globals)\n",
        "            prediction = outputs.squeeze(dim=1)\n",
        "\n",
        "            # Apply mask to the prediction tensor\n",
        "            masked_prediction = torch.masked_select(prediction, masks.bool())\n",
        "\n",
        "            # Reshape the masked_prediction tensor\n",
        "            masked_prediction = masked_prediction.view(-1, num_tasks)\n",
        "\n",
        "            # Append predictions, labels, and masks to lists\n",
        "            prediction_all.append(masked_prediction)\n",
        "            labels_all.append(labels)\n",
        "            masks_all.append(masks)\n",
        "\n",
        "        # Concatenate predictions, labels, and masks\n",
        "        prediction_all = torch.cat(prediction_all, dim=0)\n",
        "        labels_all = torch.cat(labels_all, dim=0)\n",
        "        masks_all = torch.cat(masks_all, dim=0)\n",
        "\n",
        "        # Compute RMSE for each task or overall RMSE if val_size and num_tasks are not provided\n",
        "        if val_size is not None and num_tasks is not None:\n",
        "            rmse = torch.sqrt(F.mse_loss(prediction_all[:val_size], labels_all[:val_size], reduction='mean'))\n",
        "        else:\n",
        "            rmse = torch.sqrt(F.mse_loss(prediction_all, labels_all, reduction='mean'))\n",
        "\n",
        "    return rmse.item()\n"
      ],
      "metadata": {
        "id": "WOYE9KwULjXw"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nEMUlR8FTNA"
      },
      "source": [
        "#### Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "y7bw3QTDFTNB"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    criterion = torch.nn.MSELoss(reduction='none')\n",
        "    loss = mask * criterion(output, label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHE9sKijFTNB"
      },
      "source": [
        "#### Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlPB6quoFTNB"
      },
      "source": [
        "##### Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "Qs9eNzXyFTNB"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "EDj0etEyFTNB"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "\n",
        "def train_evaluate():\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "    best_val = 0\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, len(val_set), num_tasks)\n",
        "            if score_val > best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KypHlChDFTNB"
      },
      "source": [
        "##### Function to compute test set score of the final saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "_kEzd52aFTNB"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "\n",
        "    test_labels_scaled = scaler.transform(test_set.labels)\n",
        "    test_set.labels = torch.tensor(test_labels_scaled).float()\n",
        "\n",
        "    test_score = compute_score(final_model, test_dataloader, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-4snf1TFTNB"
      },
      "source": [
        "##### Train the model and evaluate its performance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the scaler on the training set labels\n",
        "train_labels_scaled = scaler.fit_transform(train_set.labels)\n",
        "train_set.labels = torch.tensor(train_labels_scaled).float()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TEw3xlKJMaD",
        "outputId": "4e109552-9149-48b3-af1d-7f81c1238750"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.951 | Valid Score: 1.202\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 1.202 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 2/100 | Training Loss: 0.896 | Valid Score: 1.194\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 1.202 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 3/100 | Training Loss: 0.907 | Valid Score: 1.191\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 1.202 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 4/100 | Training Loss: 0.997 | Valid Score: 1.190\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 1.202 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 5/100 | Training Loss: 0.894 | Valid Score: 1.198\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 1.202 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 6/100 | Training Loss: 1.057 | Valid Score: 1.198\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 1.202 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 0.901 | Valid Score: 1.204\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 1.204 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 8/100 | Training Loss: 1.119 | Valid Score: 1.201\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 1.204 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 9/100 | Training Loss: 0.939 | Valid Score: 1.192\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 1.204 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 10/100 | Training Loss: 0.893 | Valid Score: 1.184\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 1.204 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 11/100 | Training Loss: 0.915 | Valid Score: 1.182\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 1.204 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 12/100 | Training Loss: 1.227 | Valid Score: 1.182\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 1.204 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 13/100 | Training Loss: 1.099 | Valid Score: 1.187\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 1.204 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 14/100 | Training Loss: 0.967 | Valid Score: 1.185\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 1.204 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 15/100 | Training Loss: 1.189 | Valid Score: 1.188\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 1.204 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 16/100 | Training Loss: 0.908 | Valid Score: 1.193\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 1.204 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 17/100 | Training Loss: 0.897 | Valid Score: 1.196\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 1.204 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 1.204 \n",
            "\n",
            "Test Score: 0.990 \n",
            "\n",
            "Execution time: 851.545 seconds\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ztr_DEKdFTM_",
        "Cw6ywJGtFTNA",
        "8nEMUlR8FTNA"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}