{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "i work with bbbp data"
      ],
      "metadata": {
        "id": "7mv-YGg_yUHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRL5MKMuibEm",
        "outputId": "a644aad7-a3b7-4b16-dc78-10bea677476d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dgl in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.65.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NZV0iDX7oStC"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import dgl.function as fn\n",
        "import torch.nn.functional as F\n",
        "import shutil\n",
        "from torch.utils.data import DataLoader\n",
        "import cloudpickle\n",
        "from dgl.nn import GraphConv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD07J8HXoStD"
      },
      "source": [
        "#### Set Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "b37SmcUeoStD"
      },
      "outputs": [],
      "source": [
        "current_dir = \"./\"\n",
        "checkpoint_path = current_dir + \"save_models/model_checkpoints/\" + \"checkpoint\"\n",
        "os.makedirs(checkpoint_path, exist_ok=True)\n",
        "\n",
        "best_model_path = current_dir + \"save_models/best_model/\"\n",
        "\n",
        "folder_data_temp = current_dir +\"data_temp/\"\n",
        "shutil.rmtree(folder_data_temp, ignore_errors=True)\n",
        "\n",
        "path_save = current_dir + \"graph_data.zip\"\n",
        "shutil.unpack_archive(path_save, folder_data_temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tQFbDkFoStD"
      },
      "source": [
        "#### Custom PyTorch Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Py0yB4mXoStD"
      },
      "outputs": [],
      "source": [
        "\"\"\" Classification Dataset \"\"\"\n",
        "class DGLDatasetClass(torch.utils.data.Dataset):\n",
        "    def __init__(self, address):\n",
        "            self.address=address+\".bin\"\n",
        "            self.list_graphs, train_labels_masks_globals = dgl.load_graphs(self.address)\n",
        "            num_graphs =len(self.list_graphs)\n",
        "            self.labels = train_labels_masks_globals[\"labels\"].view(num_graphs,-1)\n",
        "            self.masks = train_labels_masks_globals[\"masks\"].view(num_graphs,-1)\n",
        "            self.globals = train_labels_masks_globals[\"globals\"].view(num_graphs,-1)\n",
        "    def __len__(self):\n",
        "        return len(self.list_graphs)\n",
        "    def __getitem__(self, idx):\n",
        "        return  self.list_graphs[idx], self.labels[idx], self.masks[idx], self.globals[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-wrHVD4oStD"
      },
      "source": [
        "#### Defining Train, Validation, and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VI-ObxvsoStD",
        "outputId": "1699197e-8747-4406-e48a-28dcfb305b56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1631 203 205\n"
          ]
        }
      ],
      "source": [
        "path_data_temp = folder_data_temp + \"scaffold\"+\"_\"+str(0)\n",
        "train_set = DGLDatasetClass(address=path_data_temp+\"_train\")\n",
        "val_set = DGLDatasetClass(address=path_data_temp+\"_val\")\n",
        "test_set = DGLDatasetClass(address=path_data_temp+\"_test\")\n",
        "\n",
        "print(len(train_set), len(val_set), len(test_set))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CucGfyUdoStE"
      },
      "source": [
        "#### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "tP0ISsC7oStE"
      },
      "outputs": [],
      "source": [
        "def collate(batch):\n",
        "    # batch is a list of tuples (graphs, labels, masks, globals)\n",
        "    # Concatenate a sequence of graphs\n",
        "    graphs = [e[0] for e in batch]\n",
        "    g = dgl.batch(graphs)\n",
        "\n",
        "    # Concatenate a sequence of tensors (labels) along a new dimension\n",
        "    labels = [e[1] for e in batch]\n",
        "    labels = torch.stack(labels, 0)\n",
        "\n",
        "    # Concatenate a sequence of tensors (masks) along a new dimension\n",
        "    masks = [e[2] for e in batch]\n",
        "    masks = torch.stack(masks, 0)\n",
        "\n",
        "    # Concatenate a sequence of tensors (globals) along a new dimension\n",
        "    globals = [e[3] for e in batch]\n",
        "    globals = torch.stack(globals, 0)\n",
        "\n",
        "    return g, labels, masks, globals\n",
        "\n",
        "\n",
        "def loader(batch_size=64):\n",
        "    train_dataloader = DataLoader(train_set,\n",
        "                              batch_size=batch_size,\n",
        "                              collate_fn=collate,\n",
        "                              drop_last=False,\n",
        "                              shuffle=True,\n",
        "                              num_workers=1)\n",
        "\n",
        "    val_dataloader =  DataLoader(val_set,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=collate,\n",
        "                             drop_last=False,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1)\n",
        "\n",
        "    test_dataloader = DataLoader(test_set,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=collate,\n",
        "                             drop_last=False,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1)\n",
        "    return train_dataloader, val_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "DblrGHiMoStE"
      },
      "outputs": [],
      "source": [
        "train_dataloader, val_dataloader, test_dataloader = loader(batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upty6OXtoStE"
      },
      "source": [
        "#### Defining A GNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YKKPx7hoStE"
      },
      "source": [
        "##### Some Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "XMFdWlOOoStF"
      },
      "outputs": [],
      "source": [
        "#Bace dataset has 1 task. Some other datasets may have some more number of tasks, e.g., tox21 has 12 tasks.\n",
        "num_tasks = 1\n",
        "\n",
        "# Size of global feature of each graph\n",
        "global_size = 200\n",
        "\n",
        "# Number of epochs to train the model\n",
        "num_epochs = 100\n",
        "\n",
        "# Number of steps to wait if the model performance on the validation set does not improve\n",
        "patience = 10\n",
        "\n",
        "#Configurations to instantiate the model\n",
        "config = {\"node_feature_size\":127, \"edge_feature_size\":12, \"hidden_size\":100}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "sa61Gq_AoStF"
      },
      "outputs": [],
      "source": [
        "# class GNN(nn.Module):\n",
        "#     def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "#         super().__init__()\n",
        "#         self.config = config\n",
        "#         self.num_tasks = num_tasks\n",
        "\n",
        "#         # Node feature size\n",
        "#         self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "#         # Edge feature size\n",
        "#         self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "#         # Hidden size\n",
        "#         self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "#         self.conv1 = GraphConv(self.node_feature_size, self.hidden_size,allow_zero_in_degree=True)\n",
        "#         self.conv2 = GraphConv(self.hidden_size, self.num_tasks,allow_zero_in_degree=True)\n",
        "\n",
        "#     # def forward(self, g, in_feat):\n",
        "#     def forward(self, mol_dgl_graph, globals):\n",
        "#         mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "#         mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "#         h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "#         h = F.relu(h)\n",
        "#         h = self.conv2(mol_dgl_graph, h)\n",
        "#         mol_dgl_graph.ndata[\"h\"] = h\n",
        "#         return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code snippet defines a custom SAGEConv module that extends the nn.Module class from PyTorch. It implements the GraphSAGE convolutional operation by using DGL's message passing and reduce functions. The forward method defines the computation flow for the graph convolution layer."
      ],
      "metadata": {
        "id": "wKNPfPVCYJQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl\n",
        "from dgl.nn import GraphConv\n",
        "import dgl.function as fn\n",
        "from dgl.nn import SAGEConv\n",
        "\n",
        "class SAGEConv(nn.Module):\n",
        "    \"\"\"Graph convolution module used by the GraphSAGE model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_feat : int\n",
        "        Input feature size.\n",
        "    out_feat : int\n",
        "        Output feature size.\n",
        "    aggregator_type : str\n",
        "        Aggregator type, e.g., 'mean', 'max', 'sum'.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_feat, out_feat, aggregator_type='mean'):\n",
        "        super(SAGEConv, self).__init__()\n",
        "        self.aggregator_type = aggregator_type\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            g.update_all(\n",
        "                message_func=fn.copy_u(\"h\", \"m\"),\n",
        "                reduce_func=getattr(fn, self.aggregator_type)(\"m\", \"h_N\"),\n",
        "            )\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)"
      ],
      "metadata": {
        "id": "32aG_4T3V4U_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the `GNN` class implements a graph neural network model with two layers of SAGEConv graph convolutional layers. The node and edge features of the input graph are processed, and the output is obtained by aggregating the node features and computing the mean across the graph."
      ],
      "metadata": {
        "id": "yrdyl-7hYLM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv(self.node_feature_size, self.hidden_size, aggregator_type='mean')\n",
        "        self.conv2 = SAGEConv(self.hidden_size, self.num_tasks, aggregator_type='mean')\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n"
      ],
      "metadata": {
        "id": "9yJGr39mV5C_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZASsJhsgoStF"
      },
      "source": [
        "#### Function to Compute Score of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xwqdwimpoStF"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def compute_score(model, data_loader, val_size, num_tasks):\n",
        "    model.eval()\n",
        "    metric = roc_auc_score\n",
        "    with torch.no_grad():\n",
        "        prediction_all= torch.empty(0)\n",
        "        labels_all= torch.empty(0)\n",
        "        masks_all= torch.empty(0)\n",
        "        for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "            prediction = model(mol_dgl_graph, globals)\n",
        "            prediction = torch.sigmoid(prediction)\n",
        "            prediction_all = torch.cat((prediction_all, prediction), 0)\n",
        "            labels_all = torch.cat((labels_all, labels), 0)\n",
        "            masks_all = torch.cat((masks_all, masks), 0)\n",
        "        average = torch.tensor([0.])\n",
        "        for i in range(num_tasks):\n",
        "            a1 = prediction_all[:, i][masks_all[:,i]==1]\n",
        "            a2 = labels_all[:, i][masks_all[:,i]==1]\n",
        "            try:\n",
        "                t = metric(a2.int().cpu(), a1.cpu()).item()\n",
        "            except ValueError:\n",
        "                t = 0\n",
        "            average += t\n",
        "    return average.item()/num_tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1UWhnXOoStF"
      },
      "source": [
        "#### Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Z4jq7aSyoStG"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = torch.nn.BCEWithLogitsLoss(reduction='none', pos_weight=pos_weight)\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyFS6QzJoStG"
      },
      "source": [
        "#### Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3BkoCf7oStG"
      },
      "source": [
        "##### Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "C3j9TEy1t3L-"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "g3_RC68Gt3L-"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 0\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, len(val_set), num_tasks)\n",
        "            if score_val > best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWIOajDDoStG"
      },
      "source": [
        "##### Function to compute test set score of the final saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "p5IUQeCXoStG"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt4nxjaRoStG"
      },
      "source": [
        "##### Train the model and evaluate its performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "wL6CbJ_zoStG",
        "outputId": "4841705a-a606-4fd2-c59d-7111deee704e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.634 | Valid Score: 0.333\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.333 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 0.596 | Valid Score: 0.370\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.370 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.575 | Valid Score: 0.403\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.403 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.562 | Valid Score: 0.454\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.454 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 0.547 | Valid Score: 0.521\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.521 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 0.541 | Valid Score: 0.564\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.564 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 0.527 | Valid Score: 0.625\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.625 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 0.518 | Valid Score: 0.643\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.643 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 0.509 | Valid Score: 0.677\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.677 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.506 | Valid Score: 0.703\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.703 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 0.497 | Valid Score: 0.717\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.717 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 0.490 | Valid Score: 0.734\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.734 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 0.486 | Valid Score: 0.741\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.741 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 0.480 | Valid Score: 0.754\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.754 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 0.473 | Valid Score: 0.761\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.761 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 0.469 | Valid Score: 0.767\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.767 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 0.463 | Valid Score: 0.773\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.773 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 0.463 | Valid Score: 0.774\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.774 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 0.457 | Valid Score: 0.781\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 0.456 | Valid Score: 0.786\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.786 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 0.451 | Valid Score: 0.787\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.787 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 0.444 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.788 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 0.444 | Valid Score: 0.790\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 0.440 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.791 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 0.439 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.791 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 0.439 | Valid Score: 0.792\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.792 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 0.436 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 28/100 | Training Loss: 0.434 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 0.429 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 30/100 | Training Loss: 0.427 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 0.425 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 0.425 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.799 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 0.421 | Valid Score: 0.800\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 0.423 | Valid Score: 0.800\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 0.419 | Valid Score: 0.801\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.801 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 36/100 | Training Loss: 0.421 | Valid Score: 0.800\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.801 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 0.415 | Valid Score: 0.801\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.801 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 0.414 | Valid Score: 0.801\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.801 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 0.418 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.802 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 0.413 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 41/100 | Training Loss: 0.414 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 0.414 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.805 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 43/100 | Training Loss: 0.411 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 0.805 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 44/100 | Training Loss: 0.407 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 0.805 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 45/100 | Training Loss: 0.407 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 0.805 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 46/100 | Training Loss: 0.406 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 0.805 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 47/100 | Training Loss: 0.407 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 0.805 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 0.404 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 0.404 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 50/100 | Training Loss: 0.402 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 51/100 | Training Loss: 0.400 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 52/100 | Training Loss: 0.402 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 53/100 | Training Loss: 0.405 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 54/100 | Training Loss: 0.401 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 55/100 | Training Loss: 0.403 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 56/100 | Training Loss: 0.398 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 57/100 | Training Loss: 0.399 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 58/100 | Training Loss: 0.397 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 59/100 | Training Loss: 0.394 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 60/100 | Training Loss: 0.396 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 61/100 | Training Loss: 0.398 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 62/100 | Training Loss: 0.393 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 63/100 | Training Loss: 0.396 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 64/100 | Training Loss: 0.399 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 65/100 | Training Loss: 0.394 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 66/100 | Training Loss: 0.396 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 67/100 | Training Loss: 0.391 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 68/100 | Training Loss: 0.394 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 69/100 | Training Loss: 0.390 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 70/100 | Training Loss: 0.391 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 71/100 | Training Loss: 0.390 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 72/100 | Training Loss: 0.390 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 73/100 | Training Loss: 0.390 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 74/100 | Training Loss: 0.390 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 75/100 | Training Loss: 0.389 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 76/100 | Training Loss: 0.386 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 77/100 | Training Loss: 0.386 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 78/100 | Training Loss: 0.389 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 79/100 | Training Loss: 0.385 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 80/100 | Training Loss: 0.386 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 81/100 | Training Loss: 0.386 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 82/100 | Training Loss: 0.386 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 83/100 | Training Loss: 0.385 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 84/100 | Training Loss: 0.384 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 85/100 | Training Loss: 0.384 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 86/100 | Training Loss: 0.382 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 87/100 | Training Loss: 0.383 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 88/100 | Training Loss: 0.386 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 89/100 | Training Loss: 0.384 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 90/100 | Training Loss: 0.382 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 91/100 | Training Loss: 0.380 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 92/100 | Training Loss: 0.383 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 93/100 | Training Loss: 0.382 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 94/100 | Training Loss: 0.382 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 95/100 | Training Loss: 0.376 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 96/100 | Training Loss: 0.380 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 97/100 | Training Loss: 0.382 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 98/100 | Training Loss: 0.377 | Valid Score: 0.814\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 99/100 | Training Loss: 0.378 | Valid Score: 0.814\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 100/100 | Training Loss: 0.377 | Valid Score: 0.814\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.814 \n",
            "\n",
            "Test Score: 0.738 \n",
            "\n",
            "Execution time: 73.860 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}